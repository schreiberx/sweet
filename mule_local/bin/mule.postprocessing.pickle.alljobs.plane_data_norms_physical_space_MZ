#! /usr/bin/env python3

import sys
import math
import glob

from mule.postprocessing.JobData import *
from mule.postprocessing.JobsData import *
from mule.postprocessing.PlaneDataNormsPhysicalSpace import *
from mule.parhelper import *
import mule.utils
import mule.postprocessing.utils


"""
Steps:
* Iterate over directories provided
* For each directory:
  * Search for reference job
  * Compare all output files in reference job with output files in this directory
  * Compute differences in different norms
  * Write pickle file
"""


def _get_job(i_job_id):
    for job_id, value in jobs_data.items():
        if job_id == i_job_id:
            return value

    raise Exception(f"Fatal: job with id {i_job_id} not found")


def _process_job(job_id, job_data):
    print(f" + job_id: {job_id}")

    if 'job_benchref' in job_data['runtime.p_job_dirpath']:
        return

    is_reference_jobs = False
    has_reference_job_info = False

    # Sort out jobs which don't have a reference job id
    # These jobs are likely the reference jobs themselves
    if 'jobgeneration.reference_job_unique_id' not in job_data:
        if 'jobgeneration.reference_job' not in job_data:
            raise Exception("No reference job information found in job data")

        if not job_data['jobgeneration.reference_job']:
            raise Exception("Job has no reference job information and is no reference job!")

        print("  + reference job detected, ignoring this one")
        return

    reference_job_unique_id = job_data['jobgeneration.reference_job_unique_id']

    print(f"  + reference_job_unique_id: {reference_job_unique_id}")

    # Load reference job
    ref_job_data = _get_job(reference_job_unique_id)

    # Load all reference output files
    ref_output_files = mule.postprocessing.utils.get_job_output_files(ref_job_data)

    if len(ref_output_files) == 0:
        print("No reference files found!")
        print("*"*80)
        print("Reference directory: "+ref_job_data['jobgeneration.job_dirpath'])
        print("*"*80)
        raise Exception("Reference files not found!")

    for ref_output_file in ref_output_files:
        print(f"  + diff for: {ref_output_file}")

        ## compute errors between each solution and the reference one
        for MZ_suffix in ["_MZ_SP", "_MZ_SQ", "_MZ_FQ", "_MZ_S", "_MZ_F", "_MZ", "_S", "_F", "_SF"]:

            spl = ref_output_file.split("_t")
            MZ_file = spl[0] + MZ_suffix + "_t" + spl[1]

            print(f"     == MZ_file: {MZ_file}")
            s = None
            try:
                s = PlaneDataNormsPhysicalSpace(
                        ref_job_data['jobgeneration.job_dirpath']+'/'+ref_output_file,
                        job_data['jobgeneration.job_dirpath']+'/'+MZ_file,
                        relative_difference = True
                )

            except Exception as e:
                print("Error occured which is ignored (missing files are ignored)")
                print(str(e))
                return

            s.print("   + ")

            basename = mule.utils.remove_file_ending(MZ_file)
            pickle_filename = 'plane_data_norms_physical_space_'+basename+'.pickle'

            print(f"  + writing file {pickle_filename}")
            s.write_file(job_data['jobgeneration.job_dirpath']+'/'+pickle_filename, verbosity=1)

        ## compute errors between
        ## -> S and SF
        ## -> F and SF
        ## -> MZ_SP and S
        ## -> MZ_SP and SF
        ## -> MZ_SQ and S
        ## -> MZ_SQ and SF
        ## -> MZ_S and S
        ## -> MZ_S and SF
        ## -> MZ_F and F
        ## -> MZ_F and SF
        ## -> MZ and SF
        cmp_ref = [
                     ["_S", "_SF"],
                     ["_F", "_SF"],
                     ["_MZ_SP", "_S"],
                     ["_MZ_SP", "_SF"],
                     ["_MZ_SQ", "_S"],
                     ["_MZ_SQ", "_SF"],
                     ["_MZ_S", "_S"],
                     ["_MZ_S", "_SF"],
                     ["_MZ_F", "_F"],
                     ["_MZ_F", "_SF"],
                     ["_MZ", "_SF"]
                  ]

        for pair in cmp_ref:

            MZ_suffix_cmp = pair[0]
            MZ_suffix_ref = pair[1]

            spl = ref_output_file.split("_t")
            MZ_file_cmp = spl[0] + MZ_suffix_cmp + "_t" + spl[1]
            MZ_file_ref = spl[0] + MZ_suffix_ref + "_t" + spl[1]

            print(f"     == MZ_file: {MZ_file_cmp}")
            s = None
            try:
                s = PlaneDataNormsPhysicalSpace(
                        job_data['jobgeneration.job_dirpath']+'/'+MZ_file_ref,
                        job_data['jobgeneration.job_dirpath']+'/'+MZ_file_cmp,
                        relative_difference = True
                )

            except Exception as e:
                print("Error occured which is ignored (missing files are ignored)")
                print(str(e))
                return

            s.print("   + ")

            basename = mule.utils.remove_file_ending(MZ_file_cmp)
            spl =  basename.split("_t")

            ##pickle_filename = 'plane_data_norms_physical_space_'+basename+'_ref' + MZ_suffix_ref + '.pickle'
            pickle_filename = 'plane_data_norms_physical_space_'+spl[0]+'_ref' + MZ_suffix_ref + '_t' + spl[1] + '.pickle'

            print(f"  + writing file {pickle_filename}")
            s.write_file(job_data['jobgeneration.job_dirpath']+'/'+pickle_filename, verbosity=1)


    print("")

if len(sys.argv) > 1:
    j = JobsData(job_dirs = sys.argv[1:], verbosity=0)

else:
    jobdir_pattern = './job_bench*'
    j = JobsData(jobdir_pattern, verbosity=0)


# Get a list of all job information
jobs_data = j.get_flattened_data()

if len(jobs_data) == 0:
    raise Exception("No jobs found!")


for job_id, value in jobs_data.items():
    _process_job(job_id, value)


