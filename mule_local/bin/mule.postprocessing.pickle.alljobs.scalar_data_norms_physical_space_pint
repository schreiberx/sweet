#! /usr/bin/env python3

import sys
import math
import glob

from mule.postprocessing.JobData import *
from mule.postprocessing.JobsData import *
from mule.postprocessing.ScalarDataNormsPhysicalSpace import *
from mule.parhelper import *
import mule.utils
import mule.postprocessing.utils


"""
Steps:
* Iterate over directories provided
* For each directory:
  * Search for reference job
  * Compare all output files in reference job with output files in this directory
  * Compute differences in different norms
  * Write pickle file
"""


def _get_job(i_job_id):
    for job_id, value in jobs_data.items():
        if job_id == i_job_id:
            return value

    raise Exception(f"Fatal: job with id {i_job_id} not found")


def _process_job(job_id, job_data):
    print(f" + job_id: {job_id}")

    is_reference_jobs = False
    has_reference_job_info = False

    # Sort out jobs which don't have a reference job id
    # These jobs are likely the reference jobs themselves
    if 'jobgeneration.reference_job_unique_id' not in job_data:
        if 'jobgeneration.reference_job' not in job_data:
            raise Exception("No reference job information found in job data")

        if not job_data['jobgeneration.reference_job']:
            raise Exception("Job has no reference job information and is no reference job!")

        print("  + reference job detected, ignoring this one")
        return

    reference_job_unique_id = job_data['jobgeneration.reference_job_unique_id']

    print(f"  + reference_job_unique_id: {reference_job_unique_id}")

    # Load reference job
    ref_job_data = _get_job(reference_job_unique_id)

    # Load all reference output files
    ref_output_files = mule.postprocessing.utils.get_job_output_files(job_data)


    max_norm_l1_value = 0.
    max_norm_l2_value = 0.
    max_norm_linf_value = 0.
    max_norm_rms_value = 0.
    max_res_norm_l1_value = 0.

    if len(ref_output_files) == 0:
        print("No reference files found!")
        print("*"*80)
        print("Reference directory: "+ref_job_data['jobgeneration.job_dirpath'])
        print("*"*80)
        raise Exception("Reference files not found!")

    print(ref_output_files)
    for ref_output_file in ref_output_files:

        if ref_output_file.startswith("residual"):
            continue

        print(f"  + diff for: {ref_output_file}")

        assert "_iter" in ref_output_file
        idx = ref_output_file.find("_iter")
        ref_output_file_ref = ref_output_file[:idx] + ref_output_file[idx + 8:]

        s = None
        try:
            s = ScalarDataNormsPhysicalSpace(
                    ref_job_data['jobgeneration.job_dirpath']+'/'+ref_output_file_ref,
                    job_data['jobgeneration.job_dirpath']+'/'+ref_output_file
            )

        except Exception as e:
            print("Error occured which is ignored (missing files are ignored)")
            print(str(e))
            return

        s.print("   + ")

        basename = mule.utils.remove_file_ending(ref_output_file)
        pickle_filename = 'scalar_data_norms_physical_space_'+basename+'.pickle'

        print(f"  + writing file {pickle_filename}")
        s.write_file(job_data['jobgeneration.job_dirpath']+'/'+pickle_filename, verbosity=1)

        max_norm_l1_value = max(max_norm_l1_value, s.norm_l1_value)
        max_norm_l2_value = max(max_norm_l2_value, s.norm_l2_value)
        max_norm_linf_value = max(max_norm_linf_value, s.norm_linf_value)
        max_norm_rms_value = max(max_norm_rms_value, s.norm_rms_value)
        max_res_norm_l1_value = max(max_res_norm_l1_value, s.res_norm_l1_value)

    #########pickle_filename = 'scalar_data_norms_physical_space_max_in_time_'+basename+'.pickle'

    #########print(f"  + writing file {pickle_filename}")
    #########s.write_file(job_data['jobgeneration.job_dirpath']+'/'+pickle_filename, verbosity=1)

    print("")

if len(sys.argv) > 1:
    j = JobsData(job_dirs = sys.argv[1:], verbosity=0)

else:
    jobdir_pattern = './job_bench*'
    j = JobsData(jobdir_pattern, verbosity=0)


# Get a list of all job information
jobs_data = j.get_flattened_data()

if len(jobs_data) == 0:
    raise Exception("No jobs found!")


for job_id, value in jobs_data.items():
    _process_job(job_id, value)


